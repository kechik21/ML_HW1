	House Prices - Advanced Regression Techniques

	კონკურსის ფარგლებში ჩვენი მთავარი მიზანი იყო მოცემულ მონაცემებზე დაყრდნობით , განგვესაზღვრა სახლის ფასები. ამისთვის კი, თავდაპირველად დავიწყე მოცემული
	მონაცემების მიმოხილვით,როგორ იყო ესა თუ ის feature დამოკიდებული სახლის ფასზე, იწვევდა თუ არა მის ზდას/შემცირებას, ასევე შევეცადე დამედგინა როგორ იყვნენ 
	დაკავშირებული არამხოლოდ ფასთან, ერთმანეთთანაც.მიმოხილვის შემდეგ შევავსე ზოგიერთი მონაცემი, დავყავი კატეგორიულ და რიცხვობრი დეითად და ცალ-ცალკე დავამუშავე 
	ისინი.კატეგორიული მონაცემების შემთხვევაში, ასევე დავყავი დეითა 2 ნაწილად: Ordinal & Nominal და ასევე განსხვავებულად დავამუშავე ისინი .მონაცემებზე დაყრდნობით,
	გავფილტრე მათი ნაწილი, რომელიც ან გავლენას არ ახდენდა სახლის ფასზე, ან ძალიან დიდი რაოდენობით missing values შეიცავდა, ან მაღალ-კორელირებული იყო სხვა
	feature-თან. ამასთან ერთად, შევეცადე რამდენიმე მათგანი მომექცია ერთ, ახალ მახასიათებელში და შესაბამისად, გავასუფთავე ის მახასიათებლები, რომელიც ახლის
	შექმნისათმის გამოვიყენე. 


	🔹	რეპოზიტორის სტრუქტურა
		model_experiment.ipynb -> ყველაზე მნიშვნელოვანი ნაწილი, აქ ვამუშავებ დეითას, Cleaning, Feature Engineering, Feature Selection და Training ნაწილები.
		model_inference.ipynb  -> ხდება test set-ზე პროგნოზი, საუკეთესო მოდელი იყო XGBoost და მისი საშუალებით დავაგენერირე submissions.
		README.md -> აღწერილია მუშაობის პროცესი, რა მიდგომები და ხერხები გამოვიყენე და რა შედეგი ჰქონდა.
		

	🔹	Feature Engineering
		როგორც უკვე აღვნიშნე, data დავყავი 2 ნაწილად: categorical & numerical. Categorical მოიცავდა object-ებს, numerical კი int64, float64-ს. რადგანაც საბოლოოდ
 		მჭირდებოდა, რომ მთლიანი დეითა ყოფილიყო რიცხვობრივი, კატეგორიული დეითა უნდა გადამეყვანა რიცხვობრივში. ამისათვის, იგი დავყავი 2 ნაწილად :
  		ordinal და nominal. Ordinal-ში მოვაქციე ის მონაცემები, რომელთა მიმდევრობას/რენქინგს მნიშვნელობა ჰქონდა,ხოლო nominal-ში კი ის მახასიათებლები,
  	 	რომელთა მიმდევრობასაც დიდად არ აქვს მნიშვნელობა. შესაბამისად, გამოვიყენე Woe encoding და One Hot encoding და ასე გადავიყვანე კატეგორიული დეითა რიცხვობრივში.
		Nan მნიშვნელობების დასამუშავებლად, თავდაპირველად ვნახე, თუ მახასიათებლების რა პროცენტული მაჩვენებელი იყო იგი.მის შემდეგ განსხვავებულად მივუდექი ისევ კატეგორიულ და რიცხობრივ
  		დეითას. ატეგორიული სვეტებისთვის (object ტიპის) – ივსება მოდალური მნიშვნელობით,რიცხვითი სვეტებისთვის – ივსება საშუალო მნიშვნელობით.
		Cleaning მეთოდებისთვის კი, როგორც უკვე აღვნიშნე, მოვიშორე მონაცემები, რომელთა missing values ჰქონდა ძალიან დიდი missing percentage, ამასთან ერთად, კორელაციის
 		საშუალებით მოვიშორე იმ წყვილებიდან ერთ-ერთი , რომელთან ცქონდათ ძალიან მაღალი კორელაციის მაჩვენებელი (რიცხობრივ დეითაში, გარდაქმნის შემდეგ, იგივე ვქენი
  		კატეგორიულებისთვის). ამასთან ერთად დავდროფე ის მონაცემებიც, რომელთა ძალიან დიდი ნაწილი იყო ერთი და იგივე და ბევრს არაფერს გვეუბნებოდა სახლის 
  		ფასებზე (Redundant Data). ასევე, შევქმენი ახალი features და მოვიშორე ისინი(ნაწილობრივ), რომლებიც მათ შესაქმნელად გამოვიყენე. 

	🔹	Feature Selection
		3 მონაცემის 93% იყო დაკარგული , ხოლო 1-ის - 80%, შესაბამისად, მათი შევსების ნაცვლად, უბრალოდ მოვიშორე ეს მონაცემები.ასევე, შევქმენი ახალი features და
		მოვიშორე ისინი(ნაწილობრივ), რომლებიც მათ შესაქმნელად გამოვიყენე. Pearson კორელაციის მატრიცის საშუალებით გამოითიშა მაღალი კორელაციის მქონე მახასიათებლები (multicollinearity-ის
		თავიდან ასაცილებლად).Feature Importance (Tree-based models)	Random Forest და XGBoost-მოდელების feature_importances_ გამოყენებით შეფასდა თითოეული 
		მახასიათებლის გავლენა.Lasso Regularization	L1 რეგულარიზაციის მეშვეობით არარელევანტური მახასიათებლების წონა შემცირდა ნულამდე.
		


	🔹	Training
		დამუშავებულ დეითას ვტესტავ 4 სხვადასხვა რეგრესიის მოდელზე, თითოეულში ვიყენებ პარამეტრების ოპტიმიზაციას GridSearchCV-ს საშუალებით და საბოლოოდ ვგლოგავ 
		MLflow-ში შესაბამის მეტრიკებს.გამოყენებული მოდელებია: 
			• Linear Regression
			• Lasso Regression (L1 regularization – ხელს უშლის overfitting-ს)
			• Random Forest Regressor (ensemble მეთოდი, არაწრფივი დამოკიდებულებების დასაფარად)
			• XGBoost Regressor (მძლავრი boosting მოდელი, მაღალი სიზუსტისთვის)

		როგორც უკვე აღვნიშნე, GridSearchCV გამოყენებულია Lasso, Random Forest და XGBoost მოდელებისთვის და თითოეულისათვის ვცადე რამდენიმე განსხვავებული პარამეტრი, 
		საუკეთესო შედეგის მისაღებად ,კერძოდ :Lasso -> alpha,Random Forest-> n_estimators, max_depth, min_samples_split, XGBoost-> n_estimators, max_depth, learning_rate, subsample
		ხოლო Cross-validation (cv=3 ან cv=5)-ს ვიყენებ საბოლოო შეფასებისთვის და ასევე overfitting-ისგან თავის დასაცავად.

		საბოლოო მოდელის შესარჩევად დავთვალე რამდენიმე სიდიდე და მათ მონაცემებზე დაყრდნობით, ავარჩიე საუკეთესო მოდელიR² და Adjusted R² – აჩვენებს, რამდენად კარგად ახსნის მოდელი მიზნობრივ ცვლადს.
			• RMSE და MAE – ზომავს შეცდომების საშუალო მნიშვნელობას.
			• RMSLE – სასარგებლოა იმ შემთხვევებში, როცა მნიშვნელოვანია ლოგარითმული სხვაობა (მაგ. ზრდის ტემპი).
			• F-statistic – მოდელის სტატისტიკური მნიშვნელობის მაჩვენებელი.
			• CV_RMSE – მნიშვნელოვანი მეტრიკა, რადგან ის ასახავს მოდელის ხარისხს cross-validation-ით.
		საბოლოო არჩევანი გავაკეთე იმ  მოდელზე, რომელსაც ჰქონდა დაბალი CV_RMSE-ს  და მაღალი R²/Adjusted R²-ს . ჩემს შემთვევაში, საუკეთესო ვარიანტი იყო XGBoost.



	🔹	MLflow tracking
		• MLflow ექსპერიმენტების ბმული :  https://dagshub.com/kechik21/ML_HW1.mlflow/#/experiments/0

			

		• ჩაწერილი მეტრიკების აღწერა:
			მეტრიკა:									აღწერა:
			R2											კორელაციის ხარისხი (0–1), რაც უფრო ახლოსაა 1-სთან, მით უკეთესი
			Adjusted R2									R²-ის გაწონასწორებული ვერსია – ითვალისწინებს პარამეტრების რაოდენობას
			RMSE										Root Mean Squared Error – საშუალო კვადრატული შეცდომის ფესვი
			MAE	Mean Absolute Error  					საშუალო აბსოლუტური შეცდომა
			RMSLE Root Mean Squared Log Error 			შესაფერისია ზრდის სიჩქარის შესაფასებლად
			F-statistic									ტესტი მოდელის მნიშვნელობის შესაფასებლად
			CV_RMSE	Cross-validated RMSE 				გვიჩვენებს მოდელის გენერალიზაციის უნარს


		• საუკეთესო მოდელის შედეგები: XGBoost
			Metric:                                    						Value:
			R2											0.9228469946005836
			MAE											13330.900573096
			Adjusted_R2									0.9038092400215069
			RMSE										19481.427980328255
			F-statistic									50.18915620278238	
			CV_RMSE										22838.34917057252
			RMSLE										0.11230725416



	Final Score : Score: 0.13273
